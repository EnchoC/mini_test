{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    data = pd.DataFrame(iris.data, columns=[i.split(' (')[0].replace(' ','_') for i in iris.feature_names])\n",
    "    data['label'] = iris.target\n",
    "    X = np.array(data.iloc[:,:-1])\n",
    "    y = np.array(data.iloc[:,-1])\n",
    "    y = np.array([1 if i==0 else -1 for i in y])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.4, 2.8, 5.6, 2.2]), -1)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯朴素贝叶斯\n",
    "import math\n",
    "from functools import reduce\n",
    "class NaiveBayes(object):\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "    \n",
    "    def mean(self, X):\n",
    "        return sum(X) / float(len(X))\n",
    "    \n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X)\n",
    "        return np.sqrt( sum([(x-avg)**2 for x in X]) / float(len(X)) )\n",
    "    \n",
    "    def separateByClass(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        separated = {i:[] for i in labels}\n",
    "        for label, value in zip(y, X):\n",
    "            separated[label].append(value)\n",
    "        return separated\n",
    "    \n",
    "    def calculateProbability(self, x, mean, stdev):\n",
    "        return (1 / (math.sqrt(2*math.pi) * stdev)) * np.exp( -(x-mean)**2 / (2 * stdev**2) )\n",
    "    \n",
    "    def calculateClassProbabilities(self, x, mean, stdev):\n",
    "        return reduce(lambda x,y: x*y, self.calculateProbability(x ,mean, stdev))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.rdim, self.cdim = X.shape\n",
    "        self.data = self.separateByClass(X, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if not self.data: raise Exception('the model need train data')\n",
    "        probability = {label:self.calculateClassProbabilities(x ,self.mean(value),self.stdev(value)) \\\n",
    "                for label,value in self.data.items()}\n",
    "        return list(probability.keys())[list(probability.values()).index(max(probability.values()))]\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right_cnt = [1 for X, y in zip(X_test, y_test) if y == self.predict(X)]\n",
    "        return sum(right_cnt)/float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NaiveBayes()\n",
    "model.fit(X,y)\n",
    "model.predict(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes(object):\n",
    "    def __init__(self):\n",
    "        self.priori = None\n",
    "        self.cond = None\n",
    "        self.result = None\n",
    "    \n",
    "    def separateByClass(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        separated = {i:[] for i in labels}\n",
    "        for label, value in zip(y, X):\n",
    "            separated[label].append(value)\n",
    "        return separated\n",
    "    \n",
    "    def priori_probability(self, separated):\n",
    "        return {k:float(len(v))/float(self.rdim) for k, v in separated.items()}\n",
    "            \n",
    "    def conditional_probability(self, separated):\n",
    "        pro = {}\n",
    "        for k,v in separated.items():\n",
    "            pro[k], v = {}, np.array(v)\n",
    "            for i in range(self.cdim):\n",
    "                pro[k][i] = {}\n",
    "                for j in set(list(v[:,i])):\n",
    "                    pro[k][i][j] = list(v[:,i]).count(j) / len(list(v[:,i])) if not pro[k][i].get(j) else pro[k][i][j]\n",
    "        return pro\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.rdim, self.cdim = X.shape\n",
    "        separated = self.separateByClass(X, y)\n",
    "        self.priori = self.priori_probability(separated)\n",
    "        self.cond = self.conditional_probability(separated)\n",
    "        self.result = self.cond.keys()\n",
    "    \n",
    "    def _predict_one(self, row):\n",
    "        max_pro = 0\n",
    "        true_label = None\n",
    "        for y in self.result:\n",
    "            tmp_pro = 1\n",
    "            for i,j in enumerate((row)):\n",
    "                tmp_pro *= self.cond[y][i][j]\n",
    "            if tmp_pro > max_pro:\n",
    "                max_pro = tmp_pro\n",
    "                true_label = y\n",
    "        return true_label\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        if not self.priori or not self.cond or not self.result: \n",
    "            raise Exception('the model need train data')\n",
    "        test_cdim = X_test.shape[1]\n",
    "        if test_cdim != self.cdim: \n",
    "            raise Exception('predict cols number[%s] not match to the model cols number[%s]'%(test_cdim, self.cdim)) \n",
    "        pro = np.array([])\n",
    "        for row in range(test_cdim):\n",
    "            pro = np.append(pro,self._predict_one(X_test[row])) \n",
    "        return pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [1,1,1,1,1,2,2,2,2,2,3,3,3,3,3],\n",
    "    ['S','M','M','S','S','S','M','M','L','L','L','M','M','L','L'],\n",
    "    [-1,-1,1,1,-1,-1,-1,1,1,1,1,1,1,1,-1]\n",
    "])\n",
    "X, y = data[:2].T, data[-1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1', '1'], dtype='<U32')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNaiveBayes()\n",
    "model.fit(X, y)\n",
    "test = np.array([[2,'S'], [1,'L']])\n",
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [1,1,1,1,1,2,2,2,2,2,3,3,3,3,3],\n",
    "    [4,5,5,4,4,4,5,5,6,6,6,5,5,6,6],\n",
    "    [-1,-1,1,1,-1,-1,-1,1,1,1,1,1,1,1,-1]\n",
    "])\n",
    "X, y = data[:2].T, data[-1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "clf.predict(np.array([[2,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array([[4.4,  3.2,  1.3,  0.2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
